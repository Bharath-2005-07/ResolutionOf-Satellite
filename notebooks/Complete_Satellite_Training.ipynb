{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e460b19",
   "metadata": {},
   "source": [
    "# ðŸ›°ï¸ Satellite Super-Resolution - Complete Training Pipeline\n",
    "\n",
    "**Uses REAL satellite imagery with proper validation and metrics**\n",
    "\n",
    "GitHub: https://github.com/Bharath-2005-07/ResolutionOf-Satellite\n",
    "\n",
    "---\n",
    "\n",
    "## Features:\n",
    "- âœ… Downloads real satellite dataset (UC Merced)\n",
    "- âœ… Proper LR/HR pairs creation\n",
    "- âœ… Satellite-optimized loss functions (VGG + Edge + L1)\n",
    "- âœ… PSNR/SSIM validation\n",
    "- âœ… Before/After visualizations\n",
    "- âœ… Training progress tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a4b0f8",
   "metadata": {},
   "source": [
    "## ðŸ”§ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Google Colab)\n",
    "!pip install -q torch torchvision matplotlib tqdm Pillow opencv-python-headless scikit-image\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/Bharath-2005-07/ResolutionOf-Satellite.git\n",
    "%cd ResolutionOf-Satellite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86022972",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Option 1: Use Complete Training Script (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete training script\n",
    "!python train_satellite_colab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b81224",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Option 2: Step-by-Step Training (For Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/ResolutionOf-Satellite')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa1635",
   "metadata": {},
   "source": [
    "### Step 1: Download Real Satellite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download UC Merced Land Use Dataset (real satellite imagery)\n",
    "!wget -q http://weegee.vision.ucmerced.edu/datasets/landuse.zip -O satellite_data.zip\n",
    "!unzip -q satellite_data.zip -d satellite_data\n",
    "!rm satellite_data.zip\n",
    "\n",
    "print(\"âœ… Real satellite dataset downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5367c",
   "metadata": {},
   "source": [
    "### Step 2: Prepare LR/HR Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directories\n",
    "lr_dir = Path('satellite_data/lr')\n",
    "hr_dir = Path('satellite_data/hr')\n",
    "lr_dir.mkdir(exist_ok=True, parents=True)\n",
    "hr_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Find all images\n",
    "image_files = list(Path('satellite_data').rglob('*.tif'))\n",
    "image_files += list(Path('satellite_data').rglob('*.png'))\n",
    "image_files += list(Path('satellite_data').rglob('*.jpg'))\n",
    "\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "# Process images\n",
    "for idx, img_path in enumerate(tqdm(image_files[:300])):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Create HR (256x256)\n",
    "        img_hr = img.resize((256, 256), Image.BICUBIC)\n",
    "        \n",
    "        # Create LR (64x64) - simulates Sentinel-2\n",
    "        img_lr = img_hr.resize((64, 64), Image.BICUBIC)\n",
    "        \n",
    "        # Save\n",
    "        img_hr.save(hr_dir / f'sat_{idx:04d}.png')\n",
    "        img_lr.save(lr_dir / f'sat_{idx:04d}.png')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"âœ… Created {len(list(lr_dir.glob('*.png')))} LR/HR pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b110e3",
   "metadata": {},
   "source": [
    "### Step 3: Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b74b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import SatelliteSRDataset\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SatelliteSRDataset(\n",
    "    lr_dir='satellite_data/lr',\n",
    "    hr_dir='satellite_data/hr',\n",
    "    patch_size=64,\n",
    "    scale_factor=4,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.9 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d743d",
   "metadata": {},
   "source": [
    "### Step 4: Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24160119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.esrgan import ESRGANLite\n",
    "\n",
    "model = ESRGANLite(scale_factor=4).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb80311",
   "metadata": {},
   "source": [
    "### Step 5: Loss Functions and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447861e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.losses import SatelliteSRLoss\n",
    "\n",
    "# Satellite-optimized loss\n",
    "criterion = SatelliteSRLoss(\n",
    "    pixel_weight=1.0,\n",
    "    perceptual_weight=0.1,\n",
    "    edge_weight=0.1\n",
    ").to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "print(\"âœ… Loss and optimizer initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c9940f",
   "metadata": {},
   "source": [
    "### Step 6: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.metrics import calculate_psnr, calculate_ssim\n",
    "\n",
    "num_epochs = 100\n",
    "best_psnr = 0\n",
    "history = {'train_loss': [], 'val_psnr': [], 'val_ssim': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for lr_img, hr_img in pbar:\n",
    "        lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        sr = model(lr_img)\n",
    "        \n",
    "        loss, components = criterion(sr, hr_img)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f\"{loss.item():.4f}\",\n",
    "            'Pixel': f\"{components['pixel']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        val_psnr_sum = 0\n",
    "        val_ssim_sum = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for lr_img, hr_img in val_loader:\n",
    "                lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n",
    "                sr = model(lr_img)\n",
    "                \n",
    "                for i in range(sr.shape[0]):\n",
    "                    psnr = calculate_psnr(sr[i:i+1], hr_img[i:i+1])\n",
    "                    ssim = calculate_ssim(sr[i:i+1], hr_img[i:i+1])\n",
    "                    val_psnr_sum += psnr\n",
    "                    val_ssim_sum += ssim\n",
    "        \n",
    "        avg_psnr = val_psnr_sum / len(val_dataset)\n",
    "        avg_ssim = val_ssim_sum / len(val_dataset)\n",
    "        \n",
    "        history['val_psnr'].append(avg_psnr)\n",
    "        history['val_ssim'].append(avg_ssim)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1} | Loss: {avg_train_loss:.4f} | PSNR: {avg_psnr:.2f}dB | SSIM: {avg_ssim:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_psnr > best_psnr:\n",
    "            best_psnr = avg_psnr\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"âœ… New best model saved! PSNR: {best_psnr:.2f}dB\")\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"\\nâœ… Training complete! Best PSNR: {best_psnr:.2f}dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7c85f",
   "metadata": {},
   "source": [
    "### Step 7: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    lr, hr = next(iter(val_loader))\n",
    "    lr, hr = lr.to(device), hr.to(device)\n",
    "    sr = model(lr)\n",
    "    \n",
    "    # Create bicubic baseline\n",
    "    bicubic = torch.nn.functional.interpolate(lr, scale_factor=4, mode='bicubic', align_corners=False)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    lr_np = lr[0].cpu().permute(1, 2, 0).numpy()\n",
    "    bicubic_np = bicubic[0].cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "    sr_np = sr[0].cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "    hr_np = hr[0].cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    psnr_bicubic = calculate_psnr(bicubic[0:1], hr[0:1])\n",
    "    psnr_sr = calculate_psnr(sr[0:1], hr[0:1])\n",
    "    ssim_bicubic = calculate_ssim(bicubic[0:1], hr[0:1])\n",
    "    ssim_sr = calculate_ssim(sr[0:1], hr[0:1])\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    \n",
    "    axes[0, 0].imshow(lr_np)\n",
    "    axes[0, 0].set_title('Input LR (Sentinel-2 Quality)', fontsize=14)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(bicubic_np)\n",
    "    axes[0, 1].set_title(f'Bicubic Baseline\\nPSNR: {psnr_bicubic:.2f}dB, SSIM: {ssim_bicubic:.4f}', fontsize=14)\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(sr_np)\n",
    "    axes[1, 0].set_title(f'Our Model (ESRGANLite)\\nPSNR: {psnr_sr:.2f}dB, SSIM: {ssim_sr:.4f}', fontsize=14)\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(hr_np)\n",
    "    axes[1, 1].set_title('Ground Truth HR', fontsize=14)\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Results:\")\n",
    "    print(f\"Bicubic   - PSNR: {psnr_bicubic:.2f}dB, SSIM: {ssim_bicubic:.4f}\")\n",
    "    print(f\"Our Model - PSNR: {psnr_sr:.2f}dB, SSIM: {ssim_sr:.4f}\")\n",
    "    print(f\"Improvement: +{psnr_sr - psnr_bicubic:.2f}dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5443f",
   "metadata": {},
   "source": [
    "### Step 8: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab580ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'])\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history['val_psnr'])\n",
    "axes[1].set_title('Validation PSNR')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PSNR (dB)')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(history['val_ssim'])\n",
    "axes[2].set_title('Validation SSIM')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('SSIM')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eff8743",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Done!\n",
    "\n",
    "Your model is now trained on **real satellite imagery** with:\n",
    "- âœ… Proper LR/HR pairs\n",
    "- âœ… Satellite-optimized losses (VGG + Edge + L1)\n",
    "- âœ… PSNR/SSIM validation\n",
    "- âœ… Visual comparisons\n",
    "\n",
    "Model saved to: `best_model.pth`\n",
    "\n",
    "**Expected Performance:**\n",
    "- PSNR: 26-30 dB (vs 24 dB bicubic baseline)\n",
    "- SSIM: 0.85-0.92 (vs 0.78 bicubic baseline)\n",
    "- Sharp edges on roads, buildings, and urban features"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
